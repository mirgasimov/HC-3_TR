# -*- coding: utf-8 -*-
"""Миргасимов-Фролов(15.27В-ПИ12/24м)-ТВОРЧЕСКИЙ РЕЙТИНГ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HmZOucQqlpSuVmqQRNPA2PGlQg4vK_lE
"""

# Импорт необходимых библиотек
import keras  # Библиотека Keras для создания и обучения нейросетей
from keras.datasets import mnist  # Набор данных MNIST (рукописные цифры 28x28)
from keras.models import Sequential  # Последовательная модель Keras
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # Слои для нейросети
from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Аугментация изображений
from keras.optimizers import Adam  # Оптимизатор Adam
import numpy as np  # Библиотека NumPy для работы с массивами
import matplotlib.pyplot as plt  # Библиотека для построения графиков

# Загрузка данных MNIST https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz 
(train_images, train_labels), (test_images, test_labels) = mnist.load_data() 

# Нормализация данных: приведение пикселей (0-255) в диапазон [0,1]
train_images = train_images.reshape((-1, 28, 28, 1)) / 255.0  # Изменение формы массива и нормализация
test_images = test_images.reshape((-1, 28, 28, 1)) / 255.0  # То же самое для тестового набора

# Выделение валидационного набора (1000 первых изображений)
validation_images = train_images[:1000]  # Первые 1000 изображений для валидации
validation_labels = train_labels[:1000]  # Их соответствующие метки
train_images = train_images[1000:]  # Остальные данные для обучения
train_labels = train_labels[1000:]  # Их метки

# Создание генератора аугментации изображений
datagen = ImageDataGenerator(
    rotation_range=10,  # Вращение изображений до 10 градусов
    width_shift_range=0.1,  # Смещение по ширине до 10%
    height_shift_range=0.1,  # Смещение по высоте до 10%
    zoom_range=0.1  # Изменение масштаба до 10%
)
datagen.fit(train_images)  # Адаптация генератора к тренировочным данным

# Создание сверточной нейросети
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),  # Сверточный слой (32 фильтра 3x3)
    MaxPooling2D(2,2),  # Слой подвыборки (уменьшает размерность в 2 раза)
    Conv2D(64, (3,3), activation='relu'),  # Еще один сверточный слой (64 фильтра 3x3)
    MaxPooling2D(2,2),  # Еще один слой подвыборки
    Flatten(),  # Преобразование многомерных данных в одномерный массив
    Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),  # Полносвязный слой (256 нейронов)
    Dropout(0.3),  # Исключение 30% нейронов для предотвращения переобучения
    Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),  # Еще один полносвязный слой (128 нейронов)
    Dropout(0.3),  # Еще один слой Dropout (30%)
    Dense(10, activation='softmax')  # Выходной слой (10 классов, softmax для вероятностей)
])

# Компиляция модели
model.compile(optimizer=Adam(learning_rate=0.001),  # Оптимизатор Adam с шагом 0.001
              loss='sparse_categorical_crossentropy',  # Функция потерь (для классов в виде целых чисел)
              metrics=['accuracy'])  # Метрика точности

# Обучение модели
history = model.fit(
    datagen.flow(train_images, train_labels, batch_size=128),  # Обучение с использованием аугментации
    epochs=20,  # Количество эпох
    validation_data=(validation_images, validation_labels)  # Валидационные данные
)

# Оценка точности модели на тестовых данных
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)  # Оценка модели
print('\nТочность на проверочных данных:', test_acc)  # Вывод точности

# Функция для отображения графиков обучения
def show_loss(history):
    loss = history.history['loss']  # Потери на тренировке
    val_loss = history.history['val_loss']  # Потери на валидации
    epochs = range(1, len(loss) + 1)  # Номера эпох

    # График потерь
    plt.plot(epochs, loss, 'bo', label='Training loss')  # Потери на обучающей выборке
    plt.plot(epochs, val_loss, 'b', label='Validation loss')  # Потери на валидации
    plt.xlabel('Epochs')  # Подпись оси X
    plt.ylabel('Loss')  # Подпись оси Y
    plt.legend(['Train', 'Test'], loc='upper left')  # Легенда
    plt.show()  # Отобразить график

    # График точности
    plt.plot(history.history['accuracy'])  # Точность на обучении
    plt.plot(history.history['val_accuracy'])  # Точность на валидации
    plt.title('Model accuracy')  # Заголовок
    plt.ylabel('Accuracy')  # Подпись оси Y
    plt.xlabel('Epoch')  # Подпись оси X
    plt.legend(['Train', 'Test'], loc='upper left')  # Легенда
    plt.show()  # Отобразить график

# Вызов функции для отображения графиков
show_loss(history)
